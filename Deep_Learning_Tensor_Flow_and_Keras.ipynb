{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Tensor Flow and Keras",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T4r3CeNLYUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "2ec99ead-f441-4776-de84-e4c43e0cee5b"
      },
      "source": [
        "pip install tensorflow-gpu==2.0.0-rc1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/cf/2fc69ba3e59edc8333e2676fa71b40197718dea7dc1282c79955cf6b2acb/tensorflow_gpu-2.0.0rc1-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n",
            "\u001b[K     |████████████████████████████████| 380.5MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.30.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.12.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.3.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.9.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 50.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.18.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.1)\n",
            "Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 46.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.2.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.12.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (49.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.1.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHASq3aCLaWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zl0nWvMLnZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTi138CgMUv2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2ce0fb72-ef83-4302-b477-72b0301aef15"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "input_dim = 784  # 28*28\n",
        "output_dim = nb_classes = 10\n",
        "batch_size = 128\n",
        "nb_epoch = 20\n",
        "\n",
        "X_train = X_train.reshape(60000, input_dim)\n",
        "X_test = X_test.reshape(10000, input_dim)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm87_gIlMa29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "Y_train = to_categorical(y_train, nb_classes)\n",
        "Y_test = to_categorical(y_test, nb_classes)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfj8ToDdMrtG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9154a18-a726-4513-9455-575bc8162ca4"
      },
      "source": [
        "X_train[0].shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idd6_efFMuwE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "90f158c4-9341-4022-dbb4-d8a5907f994c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "\n",
        "plt.subplot(141)\n",
        "plt.imshow(X_train[123].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[123]))\n",
        "\n",
        "plt.subplot(142)\n",
        "plt.imshow(X_train[124].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[124]))\n",
        "\n",
        "plt.subplot(143)\n",
        "plt.imshow(X_train[125].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[125]))\n",
        "\n",
        "plt.subplot(144)\n",
        "plt.imshow(X_train[126].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[126]))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbhdYKJsRCaF",
        "colab_type": "text"
      },
      "source": [
        "1. In this task, you'll build an ANN and train and test it using the MNIST data. This ANN should consist of two hidden and one output layer. All hidden layers should be dense. The neuron sizes of the first layer and the second layer should be 32 and 16 respectively. Train this model 20 epochs and compare your train and test set performance with the example in the checkpoint. Is there any difference? If so, why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uununqM5MzeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(32, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(16, activation=\"relu\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89FP2wGzM9QP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3bc8799d-c15a-4871-81ef-69f7220700ad"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 25,818\n",
            "Trainable params: 25,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0VsKmVgM_Gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcjkYz8WNCEz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "fbb93ee1-bd04-4633-e5e6-5b90e091cd3a"
      },
      "source": [
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1d7372a950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1d7372a950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 1.6274 - accuracy: 0.5198\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.7069 - accuracy: 0.8145\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.5014 - accuracy: 0.8594\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.4293 - accuracy: 0.8766\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.3903 - accuracy: 0.8863\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.3638 - accuracy: 0.8941\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.3428 - accuracy: 0.9008\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.3257 - accuracy: 0.9059\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.3108 - accuracy: 0.9102\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2973 - accuracy: 0.9133\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2856 - accuracy: 0.9171\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.2748 - accuracy: 0.9206\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2644 - accuracy: 0.9234\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2552 - accuracy: 0.9260\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2466 - accuracy: 0.9289\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2385 - accuracy: 0.9315\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2313 - accuracy: 0.9333\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2244 - accuracy: 0.9357\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.2178 - accuracy: 0.9376\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2119 - accuracy: 0.9395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1d7373d2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBML1BZbNE78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "51ec6a8c-9345-4d66-b05f-21a8dcfa3c89"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.2085102808237076\n",
            "Test accuracy: 0.9366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQkHVFehQxXT",
        "colab_type": "text"
      },
      "source": [
        "The model achieved 94% accuracy in both the training and the test set. This level is lower than that of the example in the checkpoint. Since the layers include less number of neurons in this model, the model is simpler than the one of the example. This resulted in a lower performance. It seems, MNIST data requires a more complicated model than this one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "couslYNKQ1P6",
        "colab_type": "text"
      },
      "source": [
        "2. You'll also build an ANN in this task. This time, this ANN should have 5 hidden layers and 1 output layer. All the layers should be dense. The neuron numbers for the hidden layers should be 1024, 512, 256, 128 and 64. Train this model 20 epochs and test it using the same data from the previous task and compare your results. Is there any difference? If so, why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJapGJ2NGxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(1024, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "# our third dense layer\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "# our fourth dense layer\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "# our fifth dense layer\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORBg_Zl_QSIT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "51246498-059b-40f6-b8ee-4a72cf149a9b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 1024)              803840    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 1,501,770\n",
            "Trainable params: 1,501,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2dg1iZpQVMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DryQwf4QXUA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "e5f49db3-6bd6-4b76-c8ec-5b6492becad1"
      },
      "source": [
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1d7e3f6488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f1d7e3f6488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "60000/60000 [==============================] - 13s 224us/sample - loss: 1.1889 - accuracy: 0.7019\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 13s 210us/sample - loss: 0.3787 - accuracy: 0.8932\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 13s 219us/sample - loss: 0.2839 - accuracy: 0.9192\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 13s 212us/sample - loss: 0.2372 - accuracy: 0.9316\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 12s 206us/sample - loss: 0.2059 - accuracy: 0.9409\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 13s 209us/sample - loss: 0.1823 - accuracy: 0.9468\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 13s 208us/sample - loss: 0.1622 - accuracy: 0.9530\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 13s 209us/sample - loss: 0.1459 - accuracy: 0.9581\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 13s 214us/sample - loss: 0.1332 - accuracy: 0.9616\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 13s 216us/sample - loss: 0.1219 - accuracy: 0.9642\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 12s 206us/sample - loss: 0.1117 - accuracy: 0.9677\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 12s 206us/sample - loss: 0.1022 - accuracy: 0.9704\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 13s 210us/sample - loss: 0.0946 - accuracy: 0.9723\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 13s 212us/sample - loss: 0.0876 - accuracy: 0.9746\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 13s 209us/sample - loss: 0.0813 - accuracy: 0.9760\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 13s 210us/sample - loss: 0.0755 - accuracy: 0.9784\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 13s 212us/sample - loss: 0.0698 - accuracy: 0.9801\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 13s 211us/sample - loss: 0.0653 - accuracy: 0.9815\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 13s 212us/sample - loss: 0.0605 - accuracy: 0.9830\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 13s 211us/sample - loss: 0.0568 - accuracy: 0.9839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1d72280748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIjc4VwAQaFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b5695f20-004b-4576-95b6-49bb4da2ea83"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.10389775360999629\n",
            "Test accuracy: 0.9688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jAPCkBjRHx-",
        "colab_type": "text"
      },
      "source": [
        "In this case, the model achieved almost 99% accuracy in the training set and 97% accuracy in the test set. The model here is more complex than the model of the previous task and the model in the example. Because this model is more complex than the previous two models it achieved higher performance in the training set. However, the difference between the training score and test score widened a little bit. It may be a sign that this model is too complex and it started to overfit. Also, to add, it took MUCH longer to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbxgvt32RIUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}